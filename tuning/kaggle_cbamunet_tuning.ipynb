{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72a07c9d-a1f8-4c54-b812-7bad9dfb2715",
   "metadata": {},
   "source": [
    "**Note**: This notebook was executed on Kaggle due to the lack of local computational resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0bb6557d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-16T21:22:01.482867Z",
     "iopub.status.busy": "2023-12-16T21:22:01.482587Z",
     "iopub.status.idle": "2023-12-16T21:22:14.454537Z",
     "shell.execute_reply": "2023-12-16T21:22:14.453259Z"
    },
    "papermill": {
     "duration": 12.981899,
     "end_time": "2023-12-16T21:22:14.456578",
     "exception": false,
     "start_time": "2023-12-16T21:22:01.474679",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting patchify\n",
      "  Downloading patchify-0.2.3-py3-none-any.whl (6.6 kB)\n",
      "Requirement already satisfied: numpy<2,>=1 in /opt/conda/lib/python3.10/site-packages (from patchify) (1.24.3)\n",
      "Installing collected packages: patchify\n",
      "Successfully installed patchify-0.2.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install patchify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5e02304",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-12-16T21:22:14.472890Z",
     "iopub.status.busy": "2023-12-16T21:22:14.472561Z",
     "iopub.status.idle": "2023-12-16T21:22:27.292144Z",
     "shell.execute_reply": "2023-12-16T21:22:27.291369Z"
    },
    "papermill": {
     "duration": 12.830682,
     "end_time": "2023-12-16T21:22:27.294451",
     "exception": false,
     "start_time": "2023-12-16T21:22:14.463769",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import keras_tuner as kt\n",
    "from tensorflow import keras\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.layers import Conv2D, Conv2DTranspose, MaxPooling2D, Concatenate, Input, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "\n",
    "sys.path.append(os.path.join(os.getcwd(), '..', 'input', 'cbamunet-tuning'))\n",
    "sys.path.append(os.path.join(os.getcwd(), '..', 'input', 'road-segmentation-data-loader'))\n",
    "\n",
    "from cbam_unet import *\n",
    "from cbam import *\n",
    "from load_data import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5441ec05",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-16T21:22:27.310300Z",
     "iopub.status.busy": "2023-12-16T21:22:27.309604Z",
     "iopub.status.idle": "2023-12-16T21:22:27.727375Z",
     "shell.execute_reply": "2023-12-16T21:22:27.726296Z"
    },
    "papermill": {
     "duration": 0.427742,
     "end_time": "2023-12-16T21:22:27.729461",
     "exception": false,
     "start_time": "2023-12-16T21:22:27.301719",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n",
      "2.13.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "# Prevent automatic GPU memory pre-allocation\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    print(gpu)\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8cb6cd0",
   "metadata": {
    "papermill": {
     "duration": 0.00678,
     "end_time": "2023-12-16T21:22:27.743512",
     "exception": false,
     "start_time": "2023-12-16T21:22:27.736732",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 0. Get dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2282f060",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-16T21:22:27.758629Z",
     "iopub.status.busy": "2023-12-16T21:22:27.758334Z",
     "iopub.status.idle": "2023-12-16T21:22:30.410657Z",
     "shell.execute_reply": "2023-12-16T21:22:30.409655Z"
    },
    "papermill": {
     "duration": 2.66225,
     "end_time": "2023-12-16T21:22:30.412722",
     "exception": false,
     "start_time": "2023-12-16T21:22:27.750472",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data set: <_MapDataset element_spec=(TensorSpec(shape=(400, 400, 3), dtype=tf.float32, name=None), TensorSpec(shape=(400, 400, 2), dtype=tf.float32, name=None))>\n"
     ]
    }
   ],
   "source": [
    "# Read in images from directory and create tf.data.Dataset\n",
    "# Get file names\n",
    "imgs_dir = os.path.join(os.path.dirname(os.getcwd()), 'input', 'road-segmentation-ds', 'training', 'images')\n",
    "gts_dir = os.path.join(os.path.dirname(os.getcwd()), 'input', 'road-segmentation-ds', 'training', 'groundtruth')\n",
    "\n",
    "# Since using iou loss, need to one hot encode the groundtruth images\n",
    "original_dataset = create_dataset(imgs_dir, gts_dir, one_hot = True)\n",
    "\n",
    "print(f'Loaded data set: {original_dataset}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0c2e7c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-16T21:22:30.428388Z",
     "iopub.status.busy": "2023-12-16T21:22:30.428067Z",
     "iopub.status.idle": "2023-12-16T21:22:32.485440Z",
     "shell.execute_reply": "2023-12-16T21:22:32.484232Z"
    },
    "papermill": {
     "duration": 2.067464,
     "end_time": "2023-12-16T21:22:32.487552",
     "exception": false,
     "start_time": "2023-12-16T21:22:30.420088",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patched data set: <_TensorSliceDataset element_spec=(TensorSpec(shape=(128, 128, 3), dtype=tf.float32, name=None), TensorSpec(shape=(128, 128, 2), dtype=tf.float32, name=None))>\n"
     ]
    }
   ],
   "source": [
    "# Generate the patches\n",
    "patched_dataset = generate_patches(original_dataset, (128,128), 0, True, True)\n",
    "print(f'Patched data set: {patched_dataset}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "002c453f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-16T21:22:32.503974Z",
     "iopub.status.busy": "2023-12-16T21:22:32.503304Z",
     "iopub.status.idle": "2023-12-16T21:22:32.544077Z",
     "shell.execute_reply": "2023-12-16T21:22:32.543057Z"
    },
    "papermill": {
     "duration": 0.050937,
     "end_time": "2023-12-16T21:22:32.546059",
     "exception": false,
     "start_time": "2023-12-16T21:22:32.495122",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shuffled data set: <_ShuffleDataset element_spec=(TensorSpec(shape=(128, 128, 3), dtype=tf.float32, name=None), TensorSpec(shape=(128, 128, 2), dtype=tf.float32, name=None))>, no. of samples: 1600\n",
      "Train data set: <_TakeDataset element_spec=(TensorSpec(shape=(128, 128, 3), dtype=tf.float32, name=None), TensorSpec(shape=(128, 128, 2), dtype=tf.float32, name=None))>, no.of samples: 1440\n",
      "Validation data set: <_SkipDataset element_spec=(TensorSpec(shape=(128, 128, 3), dtype=tf.float32, name=None), TensorSpec(shape=(128, 128, 2), dtype=tf.float32, name=None))>, no.of samples: 160\n"
     ]
    }
   ],
   "source": [
    "# Split into train and validation split\n",
    "# Augmentation is only performed on the training split\n",
    "\n",
    "# Shuffle the dataset\n",
    "# Seed of 1 for reproducibility\n",
    "train_prop = 0.9\n",
    "num_samples = len(patched_dataset)\n",
    "\n",
    "# seed and reshuffle_each_iteration = False to prevent reshuffling after each iteration of dataset for reproducibility\n",
    "seed = 1\n",
    "shuffled_dataset = patched_dataset.shuffle(buffer_size = num_samples, seed = seed, reshuffle_each_iteration = False)  \n",
    "print(f'Shuffled data set: {shuffled_dataset}, no. of samples: {len(shuffled_dataset)}')\n",
    "\n",
    "train_size = int(train_prop*num_samples)\n",
    "train_dataset = shuffled_dataset.take(train_size)\n",
    "val_dataset = shuffled_dataset.skip(train_size)\n",
    "print(f'Train data set: {train_dataset}, no.of samples: {len(train_dataset)}')\n",
    "print(f'Validation data set: {val_dataset}, no.of samples: {len(val_dataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0e42cf0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-16T21:22:32.561820Z",
     "iopub.status.busy": "2023-12-16T21:22:32.561546Z",
     "iopub.status.idle": "2023-12-16T21:22:36.413349Z",
     "shell.execute_reply": "2023-12-16T21:22:36.412507Z"
    },
    "papermill": {
     "duration": 3.862413,
     "end_time": "2023-12-16T21:22:36.415706",
     "exception": false,
     "start_time": "2023-12-16T21:22:32.553293",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original train dataset: <_TakeDataset element_spec=(TensorSpec(shape=(128, 128, 3), dtype=tf.float32, name=None), TensorSpec(shape=(128, 128, 2), dtype=tf.float32, name=None))>\n",
      "No. of samples before augmenting: 1440\n",
      "Augmented train dataset: <_ConcatenateDataset element_spec=(TensorSpec(shape=(128, 128, 3), dtype=tf.float32, name=None), TensorSpec(shape=(128, 128, 2), dtype=tf.float32, name=None))>\n",
      "No. of samples after augmenting: 25920\n"
     ]
    }
   ],
   "source": [
    "# Augment the train split\n",
    "print(f'Original train dataset: {train_dataset}')\n",
    "print(f'No. of samples before augmenting: {len(train_dataset)}')\n",
    "\n",
    "num_images = [2, 1, 2] # [num_brightness, num_rotation, num_noise]\n",
    "augmented_train_dataset = create_augmented_dataset(train_dataset, num_images)\n",
    "\n",
    "print(f'Augmented train dataset: {augmented_train_dataset}')\n",
    "print(f'No. of samples after augmenting: {len(augmented_train_dataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "70846371",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-16T21:22:36.431971Z",
     "iopub.status.busy": "2023-12-16T21:22:36.431686Z",
     "iopub.status.idle": "2023-12-16T21:23:13.790630Z",
     "shell.execute_reply": "2023-12-16T21:23:13.789664Z"
    },
    "papermill": {
     "duration": 37.376664,
     "end_time": "2023-12-16T21:23:13.800020",
     "exception": false,
     "start_time": "2023-12-16T21:22:36.423356",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_imgs shape: (25920, 128, 128, 3)\n",
      "train_gts shape: (25920, 128, 128, 2)\n",
      "val_imgs shape: (160, 128, 128, 3)\n",
      "val_gts shape: (160, 128, 128, 2)\n"
     ]
    }
   ],
   "source": [
    "# Split augmented train dataset into train and validation. These validations will be used to validate the model while the\n",
    "# validation dataset obtained prior to augmenting the dataset will be used to test the model\n",
    "\n",
    "# Seperate the datasets into img and gt and store as np.asarray\n",
    "train_imgs = np.asarray(list(augmented_train_dataset.map(lambda img, gt: img)))\n",
    "train_gts = np.asarray(list(augmented_train_dataset.map(lambda img, gt: gt)))\n",
    "val_imgs = np.asarray(list(val_dataset.map(lambda img, gt: img)))\n",
    "val_gts = np.asarray(list(val_dataset.map(lambda img, gt: gt)))\n",
    "\n",
    "# Check shapes of np arrays\n",
    "print(f'train_imgs shape: {train_imgs.shape}')\n",
    "print(f'train_gts shape: {train_gts.shape}')\n",
    "print(f'val_imgs shape: {val_imgs.shape}')\n",
    "print(f'val_gts shape: {val_gts.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea65ec9",
   "metadata": {
    "papermill": {
     "duration": 0.008108,
     "end_time": "2023-12-16T21:23:13.815791",
     "exception": false,
     "start_time": "2023-12-16T21:23:13.807683",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 1. Define custom loss and prepare model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b36c0b52",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-16T21:23:13.831671Z",
     "iopub.status.busy": "2023-12-16T21:23:13.831350Z",
     "iopub.status.idle": "2023-12-16T21:23:14.507353Z",
     "shell.execute_reply": "2023-12-16T21:23:14.506270Z"
    },
    "papermill": {
     "duration": 0.686521,
     "end_time": "2023-12-16T21:23:14.509626",
     "exception": false,
     "start_time": "2023-12-16T21:23:13.823105",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Road pixel proportions: 0.22525987499999997, Background pixel proportions: 0.7747401249999997\n",
      "Road weight: 4.439317033271017, Background weight: 1.2907554000768973\n"
     ]
    }
   ],
   "source": [
    "# Get class weights\n",
    "# Determine class weights which will be used in model later on\n",
    "road_pixel_prop, bg_pixel_prop = get_class_weights(imgs_dir, gts_dir)\n",
    "print(f'Road pixel proportions: {road_pixel_prop}, Background pixel proportions: {bg_pixel_prop}')\n",
    "\n",
    "ROAD_WEIGHT = 1./road_pixel_prop\n",
    "BG_WEIGHT = 1./bg_pixel_prop\n",
    "print(f'Road weight: {ROAD_WEIGHT}, Background weight: {BG_WEIGHT}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "29592970",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-16T21:23:14.526494Z",
     "iopub.status.busy": "2023-12-16T21:23:14.526197Z",
     "iopub.status.idle": "2023-12-16T21:23:14.536952Z",
     "shell.execute_reply": "2023-12-16T21:23:14.536118Z"
    },
    "papermill": {
     "duration": 0.021276,
     "end_time": "2023-12-16T21:23:14.538908",
     "exception": false,
     "start_time": "2023-12-16T21:23:14.517632",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define loss function\n",
    "def flatten_arrs(y_true, y_pred):\n",
    "\n",
    "        y_true_background = K.flatten(y_true[...,0])\n",
    "        y_true_road = K.flatten(y_true[...,1:])\n",
    "\n",
    "        y_pred_background = K.flatten(y_pred[...,0])\n",
    "        y_pred_road = K.flatten(y_pred[...,1:])\n",
    "\n",
    "        return y_true_background, y_true_road, y_pred_background, y_pred_road\n",
    "\n",
    "    \n",
    "def compute_intersection(y_true, y_pred):\n",
    "\n",
    "    return tf.cast(tf.reduce_sum(y_true * y_pred), dtype = tf.float32)\n",
    "\n",
    "\n",
    "def compute_union(y_true, y_pred):\n",
    "\n",
    "    intersection = compute_intersection(y_true, y_pred)\n",
    "    return tf.cast(tf.reduce_sum(y_true), dtype = tf.float32) + tf.cast(tf.reduce_sum(y_pred), dtype = tf.float32) - intersection\n",
    "\n",
    "\n",
    "def iou(y_true, y_pred):\n",
    "\n",
    "    epsilon = 1e-7\n",
    "\n",
    "    intersection = compute_intersection(y_true, y_pred)\n",
    "    union = compute_union(y_true, y_pred)\n",
    "\n",
    "    return (intersection + epsilon)/ (union + epsilon)\n",
    "\n",
    "\n",
    "def compute_iou(y_true, y_pred, background_weight = 0.5, road_weight = 0.5):\n",
    "\n",
    "    y_true_background, y_true_road, y_pred_background, y_pred_road = flatten_arrs(y_true, y_pred)\n",
    "\n",
    "    background_iou = iou(y_true_background, y_pred_background)\n",
    "    road_iou = iou(y_true_road, y_pred_road)\n",
    "\n",
    "    return (BG_WEIGHT*background_iou) + (ROAD_WEIGHT*road_iou)\n",
    "\n",
    "\n",
    "def compute_loss(y_true, y_pred):\n",
    "\n",
    "    '''Implementation code to calculate weighted iou loss. \n",
    "\n",
    "    Args:\n",
    "        y_true: tensor of shape (batch_size, 400, 400, 1), containing pixel values of groundtruth image\n",
    "        y_pred: tensor of shape (batch_size, 400, 400, 2), containing pixel values of prediction from model. Each channel corresponds to one segmented class.\n",
    "\n",
    "    Returns:\n",
    "        loss\n",
    "    '''    \n",
    "\n",
    "    # add a constant to ensure that loss is positive when applying class weights\n",
    "    constant = 10.\n",
    "    return (1. - compute_iou(y_true, y_pred, BG_WEIGHT, ROAD_WEIGHT)) + 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "867a0246",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-16T21:23:14.556783Z",
     "iopub.status.busy": "2023-12-16T21:23:14.556148Z",
     "iopub.status.idle": "2023-12-16T21:23:14.562249Z",
     "shell.execute_reply": "2023-12-16T21:23:14.561466Z"
    },
    "papermill": {
     "duration": 0.017113,
     "end_time": "2023-12-16T21:23:14.564044",
     "exception": false,
     "start_time": "2023-12-16T21:23:14.546931",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def apply_att_and_crop(x_att_applied, x, new_size):\n",
    "\n",
    "    '''Implementation code for applying attention and concatenating it to upsampled feature map\n",
    "\n",
    "    Args:\n",
    "        x: Input features of shape (height, width, channel) from downsampled portion\n",
    "        depth: Depth in U-Net model, to decide which CBAM_Module to apply\n",
    "        new_size: Desired size of cropped image, to match with the upsampled size from deeper layers\n",
    "\n",
    "    Returns:\n",
    "        cropped features from downsmpled portion with attention applied\n",
    "    '''\n",
    "\n",
    "    # Apply attention\n",
    "    x_att_shape = tf.shape(x_att_applied)\n",
    "\n",
    "    # Calculate the crop sizes for height and width\n",
    "    h_crop_size = (x_att_shape[1] - new_size[1]) // 2\n",
    "    w_crop_size = (x_att_shape[2] - new_size[2]) // 2\n",
    "\n",
    "    # Calculate the starting and ending indices for cropping along height\n",
    "    h_start = h_crop_size\n",
    "    h_end = h_start + new_size[1]\n",
    "\n",
    "    # Calculate the starting and ending indices for cropping along width\n",
    "    w_start = w_crop_size\n",
    "    w_end = w_start + new_size[2]\n",
    "\n",
    "    # Return the cropped image tensor\n",
    "    return x_att_applied[:, h_start:h_end, w_start:w_end, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "72152abd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-16T21:23:14.580422Z",
     "iopub.status.busy": "2023-12-16T21:23:14.580115Z",
     "iopub.status.idle": "2023-12-16T21:23:14.610926Z",
     "shell.execute_reply": "2023-12-16T21:23:14.610192Z"
    },
    "papermill": {
     "duration": 0.041245,
     "end_time": "2023-12-16T21:23:14.612781",
     "exception": false,
     "start_time": "2023-12-16T21:23:14.571536",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class HyperModel(kt.HyperModel):\n",
    "    \n",
    "    def build(self, hp):\n",
    "\n",
    "        lr = hp.Choice('learning_rate', [0.01, 0.001, 0.0001])\n",
    "        pooling_dropout = hp.Boolean('pooling_dropout', default = False)\n",
    "        l2_reg_conv2d = hp.Choice('l2_reg_conv2d', [0.0, 0.01])\n",
    "        \n",
    "        cbam_depth1 = CBAM_Module(1, 64)\n",
    "        cbam_depth2 = CBAM_Module(2, 128)\n",
    "        cbam_depth3 = CBAM_Module(3, 256)\n",
    "        cbam_depth4 = CBAM_Module(4, 512)\n",
    "\n",
    "        inpt = Input(shape=(128,128,3))\n",
    "\n",
    "        x_0 = inpt\n",
    "        # encoder conv. block 1\n",
    "        x = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = 'same', activation = 'relu',\n",
    "                   kernel_initializer = 'he_normal', kernel_regularizer = keras.regularizers.L2(l2_reg_conv2d))(inpt)\n",
    "        x = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = 'same', activation = 'relu',\n",
    "                   kernel_initializer = 'he_normal', kernel_regularizer = keras.regularizers.L2(l2_reg_conv2d))(x)\n",
    "        x_1 = x\n",
    "        x = MaxPooling2D(pool_size = 2, strides = 2, padding = 'same')(x)\n",
    "        \n",
    "        if pooling_dropout:\n",
    "            x = Dropout(rate = 0.2)(x)\n",
    "            \n",
    "        # encoder conv. block 2\n",
    "        x = Conv2D(filters = 128, kernel_size = 3, strides = 1, padding = 'same', activation = 'relu',\n",
    "                   kernel_initializer = 'he_normal', kernel_regularizer = keras.regularizers.L2(l2_reg_conv2d))(x)\n",
    "        x = Conv2D(filters = 128, kernel_size = 3, strides = 1, padding = 'same', activation = 'relu',\n",
    "                   kernel_initializer = 'he_normal', kernel_regularizer = keras.regularizers.L2(l2_reg_conv2d))(x)\n",
    "        x_2 = x\n",
    "        x = MaxPooling2D(pool_size = 2, strides = 2, padding = 'same')(x)\n",
    "        \n",
    "        if pooling_dropout:\n",
    "            x = Dropout(rate = 0.2)(x)\n",
    "            \n",
    "        # encoder conv. block 3\n",
    "        x = Conv2D(filters = 256, kernel_size = 3, strides = 1, padding = 'same', activation = 'relu',\n",
    "                   kernel_initializer = 'he_normal', kernel_regularizer = keras.regularizers.L2(l2_reg_conv2d))(x)\n",
    "        x = Conv2D(filters = 256, kernel_size = 3, strides = 1, padding = 'same', activation = 'relu',\n",
    "                   kernel_initializer = 'he_normal', kernel_regularizer = keras.regularizers.L2(l2_reg_conv2d))(x)\n",
    "        x_3 = x\n",
    "        x = MaxPooling2D(pool_size = 2, strides = 2, padding = 'same')(x)\n",
    "\n",
    "        if pooling_dropout:\n",
    "            x = Dropout(rate = 0.2)(x)\n",
    "            \n",
    "        # encoder conv. block 4\n",
    "        x = Conv2D(filters = 512, kernel_size = 3, strides = 1, padding = 'same', activation = 'relu',\n",
    "                   kernel_initializer = 'he_normal', kernel_regularizer = keras.regularizers.L2(l2_reg_conv2d))(x)\n",
    "        x = Conv2D(filters = 512, kernel_size = 3, strides = 1, padding = 'same', activation = 'relu',\n",
    "                   kernel_initializer = 'he_normal', kernel_regularizer = keras.regularizers.L2(l2_reg_conv2d))(x)    \n",
    "        x_4 = x\n",
    "        x = MaxPooling2D(pool_size = 2, strides = 2, padding = 'same')(x)\n",
    "\n",
    "        if pooling_dropout:\n",
    "            x = Dropout(rate = 0.2)(x)\n",
    "            \n",
    "        # encoder conv. block 5\n",
    "        x = Conv2D(filters = 1024, kernel_size = 3, strides = 1, padding = 'same', activation = 'relu',\n",
    "                   kernel_initializer = 'he_normal', kernel_regularizer = keras.regularizers.L2(l2_reg_conv2d))(x)\n",
    "        x = Conv2D(filters = 1024, kernel_size = 3, strides = 1, padding = 'same', activation = 'relu',\n",
    "                   kernel_initializer = 'he_normal', kernel_regularizer = keras.regularizers.L2(l2_reg_conv2d))(x)\n",
    "\n",
    "        # conv transpose depth 5\n",
    "        x = Conv2DTranspose(filters = 512, kernel_size = 2, strides = 2, padding = 'same')(x)\n",
    "        attention_x_4 = cbam_depth4(x_4)\n",
    "        attention_x_4 = apply_att_and_crop(attention_x_4, x_4, tf.shape(x_4))\n",
    "        x = Concatenate(axis = -1)([attention_x_4, x])\n",
    "        # decoder conv. block 4\n",
    "        x = Conv2D(filters = 512, kernel_size = 3, strides = 1, padding = 'same', activation = 'relu',\n",
    "                   kernel_initializer = 'he_normal', kernel_regularizer = keras.regularizers.L2(l2_reg_conv2d))(x)\n",
    "        x = Conv2D(filters = 512, kernel_size = 3, strides = 1, padding = 'same', activation = 'relu',\n",
    "                   kernel_initializer = 'he_normal', kernel_regularizer = keras.regularizers.L2(l2_reg_conv2d))(x)\n",
    "\n",
    "        # conv transpose depth 4\n",
    "        x = Conv2DTranspose(filters = 256, kernel_size = 2, strides = 2, padding = 'same')(x)\n",
    "        attention_x_3 = cbam_depth3(x_3)\n",
    "        attention_x_3 = apply_att_and_crop(attention_x_3, x_3, tf.shape(x))\n",
    "        x = Concatenate(axis = -1)([attention_x_3, x])\n",
    "        # decoder conv. block 3\n",
    "        x = Conv2D(filters = 256, kernel_size = 3, strides = 1, padding = 'same', activation = 'relu',\n",
    "                   kernel_initializer = 'he_normal', kernel_regularizer = keras.regularizers.L2(l2_reg_conv2d))(x)\n",
    "        x = Conv2D(filters = 256, kernel_size = 3, strides = 1, padding = 'same', activation = 'relu',\n",
    "                   kernel_initializer = 'he_normal', kernel_regularizer = keras.regularizers.L2(l2_reg_conv2d))(x)\n",
    "\n",
    "        # conv transpose depth 3\n",
    "        x = Conv2DTranspose(filters = 128, kernel_size = 2, strides = 2, padding = 'same')(x)\n",
    "        attention_x_2 = cbam_depth2(x_2)\n",
    "        attention_x_2 = apply_att_and_crop(attention_x_2, x_2, tf.shape(x))\n",
    "        x = Concatenate(axis = -1)([attention_x_2, x])\n",
    "        # decoder conv. block 2\n",
    "        x = Conv2D(filters = 128, kernel_size = 3, strides = 1, padding = 'same', activation = 'relu',\n",
    "                   kernel_initializer = 'he_normal', kernel_regularizer = keras.regularizers.L2(l2_reg_conv2d))(x)\n",
    "        x = Conv2D(filters = 128, kernel_size = 3, strides = 1, padding = 'same', activation = 'relu',\n",
    "                   kernel_initializer = 'he_normal', kernel_regularizer = keras.regularizers.L2(l2_reg_conv2d))(x)\n",
    "\n",
    "        # conv transpose depth 2\n",
    "        x = Conv2DTranspose(filters = 64, kernel_size = 2, strides = 2, padding = 'same')(x)\n",
    "        attention_x_1 = cbam_depth1(x_1)\n",
    "        attention_x_1 = apply_att_and_crop(attention_x_1, x_1, tf.shape(x))\n",
    "        x = Concatenate(axis = -1)([attention_x_1, x])\n",
    "\n",
    "        # output conv. block\n",
    "        x = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = 'same', activation = 'relu',\n",
    "                   kernel_initializer = 'he_normal', kernel_regularizer = keras.regularizers.L2(l2_reg_conv2d))(x)\n",
    "        x = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = 'same', activation = 'relu',\n",
    "                   kernel_initializer = 'he_normal', kernel_regularizer = keras.regularizers.L2(l2_reg_conv2d))(x)\n",
    "        output = Conv2D(filters = 2, kernel_size = 1, activation = 'sigmoid')(x)\n",
    "        \n",
    "        model = tf.keras.Model(inputs = inpt, outputs = output)\n",
    "\n",
    "        optimiser_choices = ['Adam', 'SGD']\n",
    "        optimiser = hp.Choice('optimiser', optimiser_choices)\n",
    "\n",
    "        if optimiser == \"adam\":\n",
    "            optimiser = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "        elif optimiser == \"SGD\":\n",
    "            optimiser = tf.keras.optimizers.SGD(learning_rate=lr)\n",
    "\n",
    "        model.compile(optimizer = optimiser, loss = compute_loss, metrics = ['accuracy'])\n",
    "\n",
    "        return model\n",
    "\n",
    "    def fit(self, hp, model, x_train, y_train, validation_data = None, **kwargs):\n",
    "        \n",
    "        return model.fit(x_train, y_train,\n",
    "                         validation_data = validation_data,\n",
    "                         batch_size = hp.Choice('batch_size', [4, 8, 16]),\n",
    "                         **kwargs,\n",
    "                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "871f34ce",
   "metadata": {
    "papermill": {
     "duration": 0.00722,
     "end_time": "2023-12-16T21:23:14.627344",
     "exception": false,
     "start_time": "2023-12-16T21:23:14.620124",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 2. Start tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "12395904",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-16T21:23:14.642997Z",
     "iopub.status.busy": "2023-12-16T21:23:14.642757Z",
     "iopub.status.idle": "2023-12-16T21:23:14.646411Z",
     "shell.execute_reply": "2023-12-16T21:23:14.645584Z"
    },
    "papermill": {
     "duration": 0.013677,
     "end_time": "2023-12-16T21:23:14.648326",
     "exception": false,
     "start_time": "2023-12-16T21:23:14.634649",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "CONTINUE_TUNE = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e1cd5a08",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-16T21:23:14.664077Z",
     "iopub.status.busy": "2023-12-16T21:23:14.663817Z",
     "iopub.status.idle": "2023-12-16T21:24:19.393153Z",
     "shell.execute_reply": "2023-12-16T21:24:19.392405Z"
    },
    "papermill": {
     "duration": 64.740471,
     "end_time": "2023-12-16T21:24:19.396129",
     "exception": false,
     "start_time": "2023-12-16T21:23:14.655658",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if CONTINUE_TUNE:\n",
    "    source_path = os.path.join(os.path.dirname(os.getcwd()), 'input', 'cbamunet-tuning-trials', 'cbam_tuning')\n",
    "    destination_path = os.path.join(os.getcwd(), 'cbam_tuning')\n",
    "    shutil.copytree(source_path, destination_path)\n",
    "    tuner = kt.BayesianOptimization(\n",
    "            HyperModel(),\n",
    "            objective = 'val_loss',\n",
    "            max_trials = 25,\n",
    "            directory = 'cbam_tuning',\n",
    "            overwrite = False,\n",
    "            project_name = 'cbam_tuning_run1'\n",
    "            )\n",
    "\n",
    "else:\n",
    "    tuner = kt.BayesianOptimization(\n",
    "        HyperModel(),\n",
    "        objective = 'val_loss',\n",
    "        max_trials = 25,\n",
    "        directory = 'cbam_tuning',\n",
    "        project_name = 'cbam_tuning_run1'\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "43e47e91",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-16T21:24:19.413575Z",
     "iopub.status.busy": "2023-12-16T21:24:19.412870Z",
     "iopub.status.idle": "2023-12-16T21:24:19.417657Z",
     "shell.execute_reply": "2023-12-16T21:24:19.416906Z"
    },
    "papermill": {
     "duration": 0.015792,
     "end_time": "2023-12-16T21:24:19.420039",
     "exception": false,
     "start_time": "2023-12-16T21:24:19.404247",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search space summary\n",
      "Default search space size: 5\n",
      "learning_rate (Choice)\n",
      "{'default': 0.01, 'conditions': [], 'values': [0.01, 0.001, 0.0001], 'ordered': True}\n",
      "pooling_dropout (Boolean)\n",
      "{'default': False, 'conditions': []}\n",
      "l2_reg_conv2d (Choice)\n",
      "{'default': 0.0, 'conditions': [], 'values': [0.0, 0.01], 'ordered': True}\n",
      "optimiser (Choice)\n",
      "{'default': 'Adam', 'conditions': [], 'values': ['Adam', 'SGD'], 'ordered': False}\n",
      "batch_size (Choice)\n",
      "{'default': 4, 'conditions': [], 'values': [4, 8, 16], 'ordered': True}\n"
     ]
    }
   ],
   "source": [
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "703653bd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-16T21:24:19.436855Z",
     "iopub.status.busy": "2023-12-16T21:24:19.436610Z",
     "iopub.status.idle": "2023-12-17T00:37:18.904196Z",
     "shell.execute_reply": "2023-12-17T00:37:18.902431Z"
    },
    "papermill": {
     "duration": 11579.489972,
     "end_time": "2023-12-17T00:37:18.918130",
     "exception": false,
     "start_time": "2023-12-16T21:24:19.428158",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 25 Complete [00h 25m 16s]\n",
      "val_loss: 9.048707962036133\n",
      "\n",
      "Best val_loss So Far: 6.797310829162598\n",
      "Total elapsed time: 03h 12m 59s\n"
     ]
    }
   ],
   "source": [
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
    "tuner.search(train_imgs, train_gts,\n",
    "            validation_data = (val_imgs, val_gts),\n",
    "            epochs = 100,\n",
    "            callbacks = [stop_early])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b093ca",
   "metadata": {
    "papermill": {
     "duration": 0.0082,
     "end_time": "2023-12-17T00:37:18.935625",
     "exception": false,
     "start_time": "2023-12-17T00:37:18.927425",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 3. Analysis of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d6387482",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-17T00:37:18.952643Z",
     "iopub.status.busy": "2023-12-17T00:37:18.952270Z",
     "iopub.status.idle": "2023-12-17T00:37:18.960671Z",
     "shell.execute_reply": "2023-12-17T00:37:18.959764Z"
    },
    "papermill": {
     "duration": 0.019334,
     "end_time": "2023-12-17T00:37:18.962543",
     "exception": false,
     "start_time": "2023-12-17T00:37:18.943209",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in cbam_tuning/cbam_tuning_run1\n",
      "Showing 10 best trials\n",
      "Objective(name=\"val_loss\", direction=\"min\")\n",
      "\n",
      "Trial 15 summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.01\n",
      "pooling_dropout: True\n",
      "l2_reg_conv2d: 0.0\n",
      "optimiser: SGD\n",
      "batch_size: 16\n",
      "Score: 6.797310829162598\n",
      "\n",
      "Trial 21 summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.01\n",
      "pooling_dropout: False\n",
      "l2_reg_conv2d: 0.0\n",
      "optimiser: SGD\n",
      "batch_size: 16\n",
      "Score: 7.055900573730469\n",
      "\n",
      "Trial 01 summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.001\n",
      "pooling_dropout: False\n",
      "l2_reg_conv2d: 0.0\n",
      "optimiser: SGD\n",
      "batch_size: 16\n",
      "Score: 7.1150922775268555\n",
      "\n",
      "Trial 03 summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.001\n",
      "pooling_dropout: True\n",
      "l2_reg_conv2d: 0.0\n",
      "optimiser: SGD\n",
      "batch_size: 16\n",
      "Score: 7.579310417175293\n",
      "\n",
      "Trial 05 summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.001\n",
      "pooling_dropout: False\n",
      "l2_reg_conv2d: 0.0\n",
      "optimiser: SGD\n",
      "batch_size: 4\n",
      "Score: 8.634018898010254\n",
      "\n",
      "Trial 00 summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.01\n",
      "pooling_dropout: False\n",
      "l2_reg_conv2d: 0.0\n",
      "optimiser: SGD\n",
      "batch_size: 4\n",
      "Score: 8.952608108520508\n",
      "\n",
      "Trial 18 summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.001\n",
      "pooling_dropout: True\n",
      "l2_reg_conv2d: 0.0\n",
      "optimiser: SGD\n",
      "batch_size: 8\n",
      "Score: 8.968579292297363\n",
      "\n",
      "Trial 23 summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.01\n",
      "pooling_dropout: True\n",
      "l2_reg_conv2d: 0.0\n",
      "optimiser: SGD\n",
      "batch_size: 4\n",
      "Score: 8.977455139160156\n",
      "\n",
      "Trial 19 summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.01\n",
      "pooling_dropout: False\n",
      "l2_reg_conv2d: 0.0\n",
      "optimiser: Adam\n",
      "batch_size: 16\n",
      "Score: 8.999563217163086\n",
      "\n",
      "Trial 17 summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.01\n",
      "pooling_dropout: False\n",
      "l2_reg_conv2d: 0.01\n",
      "optimiser: SGD\n",
      "batch_size: 4\n",
      "Score: 9.031100273132324\n"
     ]
    }
   ],
   "source": [
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0a2d1ea0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-17T00:37:18.979140Z",
     "iopub.status.busy": "2023-12-17T00:37:18.978867Z",
     "iopub.status.idle": "2023-12-17T00:37:18.984383Z",
     "shell.execute_reply": "2023-12-17T00:37:18.983485Z"
    },
    "papermill": {
     "duration": 0.015873,
     "end_time": "2023-12-17T00:37:18.986214",
     "exception": false,
     "start_time": "2023-12-17T00:37:18.970341",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.01, 'pooling_dropout': True, 'l2_reg_conv2d': 0.0, 'optimiser': 'SGD', 'batch_size': 16}\n"
     ]
    }
   ],
   "source": [
    "best_hp = tuner.get_best_hyperparameters()[0]\n",
    "print(best_hp.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a39f09",
   "metadata": {
    "papermill": {
     "duration": 0.007623,
     "end_time": "2023-12-17T00:37:19.001703",
     "exception": false,
     "start_time": "2023-12-17T00:37:18.994080",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 4155267,
     "sourceId": 7187350,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4037500,
     "sourceId": 7195369,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4121713,
     "sourceId": 7195387,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4165347,
     "sourceId": 7218667,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30615,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 11723.968654,
   "end_time": "2023-12-17T00:37:22.105776",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-12-16T21:21:58.137122",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
